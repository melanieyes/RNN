{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d18b44e-52dd-42ff-9827-6442a7f11550",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7396594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.18.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tqdm in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (4.66.4)\n",
      "Requirement already satisfied: requests in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (2.32.2)\n",
      "Requirement already satisfied: torch>=2.3.0 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torchtext) (1.26.4)\n",
      "Requirement already satisfied: filelock in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from requests->torchtext) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
      "Downloading torchtext-0.18.0-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchtext\n",
      "Successfully installed torchtext-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069c60c4-ccb8-403c-b16a-7266f9a1ff6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'learning', 'ai']\n",
      "['ai', 'is', 'a', 'cs', 'topic']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quangvinh/miniconda3/envs/torchenv/lib/python3.12/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "sample1 = 'We are learning AI'\n",
    "sample2 = 'AI is a CS topic'\n",
    "\n",
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "sample1_tokens = tokenizer(sample1)\n",
    "sample2_tokens = tokenizer(sample2)\n",
    "\n",
    "print(sample1_tokens)\n",
    "print(sample2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125ed1e-9f13-408c-8f79-9bb4bdc58572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "700ffe54-f581-45aa-98a3-441c1dc85b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "sample1 = 'We are learning AI'\n",
    "sample2 = 'AI is a CS topic'\n",
    "data = [sample1, sample2]\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create vocabulary\n",
    "vocab_size = 8\n",
    "vocab = build_vocab_from_iterator(yield_tokens(data),\n",
    "                                  max_tokens=vocab_size,\n",
    "                                  specials=[\"<unk>\", \n",
    "                                            \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e337b92e-bf41-4d10-afbe-096418095da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning': 7,\n",
       " 'is': 6,\n",
       " 'are': 4,\n",
       " 'a': 3,\n",
       " 'cs': 5,\n",
       " 'ai': 2,\n",
       " '<pad>': 1,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3ac4d-3a85-4d56-85ca-e8ee9c969a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9f1d59f-c4b5-42d1-bb56-54b51ea50c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'learning', 'ai']\n",
      "[0, 4, 7, 2]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(sample1)\n",
    "print(tokens) \n",
    "\n",
    "sample1_tokens = [vocab[token] for token in tokens]\n",
    "print(sample1_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495dad80-c3fb-4635-9d67-c7897c601c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'is', 'a', 'cs', 'topic']\n",
      "[2, 6, 3, 5, 0]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(sample2)\n",
    "print(tokens) \n",
    "\n",
    "sample2_tokens = [vocab[token] for token in tokens]\n",
    "print(sample2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c175a8-1309-4e38-88a5-b678318514b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ae1cfe-b2a0-44d1-99ce-f537a74ab151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Sample 1: tensor([0, 4, 7, 2, 1])\n",
      "Vectorized Sample 2: tensor([2, 6, 3, 5, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def vectorize(text, vocab, seq_len):\n",
    "    tokens = tokenizer(text)    \n",
    "    tokens = [vocab[token] for token in tokens] \n",
    "    \n",
    "    num_pads = sequence_length - len(tokens)\n",
    "    tokens = tokens[:sequence_length] + [vocab[\"<pad>\"]]*num_pads\n",
    "    \n",
    "    return torch.tensor(tokens, dtype=torch.long)\n",
    "\n",
    "# Vectorize the samples\n",
    "sequence_length = 5\n",
    "vectorized_sample1 = vectorize(sample1, vocab, \n",
    "                               sequence_length)\n",
    "vectorized_sample2 = vectorize(sample2, vocab, \n",
    "                               sequence_length)\n",
    "\n",
    "print(\"Vectorized Sample 1:\", vectorized_sample1)\n",
    "print(\"Vectorized Sample 2:\", vectorized_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897b7f8e-1118-45e5-9b8d-6c31a7fe4113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 0, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "sample3 = 'AI topic in CS is difficult'\n",
    "vectorized_sample3 = vectorize(sample3, vocab, \n",
    "                               sequence_length)\n",
    "print(vectorized_sample3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a026fa8-8860-49e1-a621-18596279af5d",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7fa0ebb-c8e0-4ef3-9ea1-bdca2c51c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1882,  0.5530,  1.6267,  0.7013],\n",
      "        [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
      "        [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
      "        [-1.3083, -0.0987,  0.7647, -0.3680],\n",
      "        [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
      "        [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
      "        [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
      "        [ 0.4309, -1.3067, -0.8823,  1.5977]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 8\n",
    "embed_dim = 4\n",
    "embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "custom_weights = torch.tensor( [[-0.1882,  0.5530,  1.6267,  0.7013],\n",
    "                                [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
    "                                [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
    "                                [-1.3083, -0.0987,  0.7647, -0.3680],\n",
    "                                [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
    "                                [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
    "                                [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
    "                                [ 0.4309, -1.3067, -0.8823,  1.5977]]).float()\n",
    "embedding.weight = nn.Parameter(custom_weights)\n",
    "print(embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a027791-dc92-4ac7-8fb7-20c68d528a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59e8091c-b48c-479e-afb4-500f25f75835",
   "metadata": {},
   "source": [
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab9d2b8-bc27-45ff-9860-27d5eb74d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1882,  0.5530,  1.6267,  0.7013],\n",
      "        [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
      "        [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
      "        [-1.3083, -0.0987,  0.7647, -0.3680],\n",
      "        [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
      "        [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
      "        [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
      "        [ 0.4309, -1.3067, -0.8823,  1.5977]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 8\n",
    "embed_dim = 4\n",
    "embedding = nn.Embedding(vocab_size, \n",
    "                         embed_dim)\n",
    "\n",
    "custom_weights = torch.tensor( [[-0.1882,  0.5530,  1.6267,  0.7013],\n",
    "                                [ 1.7840, -0.8278, -0.2701,  1.3586],\n",
    "                                [ 1.0281, -1.9094,  0.3182,  0.4211],\n",
    "                                [-1.3083, -0.0987,  0.7647, -0.3680],\n",
    "                                [ 0.2293,  1.3255,  0.1318,  2.0501],\n",
    "                                [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
    "                                [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
    "                                [ 0.4309, -1.3067, -0.8823,  1.5977]]).float()\n",
    "embedding.weight = nn.Parameter(custom_weights)\n",
    "print(embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcffa230-ef6c-450d-a781-e9b20f727dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([0, 4, 7, 2, 1], dtype=torch.long)\n",
    "label = torch.tensor([1], dtype=torch.float)\n",
    "\n",
    "x = embedding(data)\n",
    "x = nn.Flatten(0)(x)\n",
    "x = nn.Linear(20, 1)(x)\n",
    "output = nn.Sigmoid()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49429089-131c-414f-94a6-4a2dccd17b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1872,  0.5520,  1.6277,  0.7023],\n",
      "        [ 1.7850, -0.8288, -0.2711,  1.3596],\n",
      "        [ 1.0291, -1.9084,  0.3172,  0.4221],\n",
      "        [-1.3083, -0.0987,  0.7647, -0.3680],\n",
      "        [ 0.2303,  1.3265,  0.1308,  2.0511],\n",
      "        [ 0.4058, -0.6624, -0.8745,  0.7203],\n",
      "        [ 0.5582,  0.0786, -0.6817,  0.6902],\n",
      "        [ 0.4299, -1.3057, -0.8833,  1.5987]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.BCELoss()(output, label)\n",
    "optimizer = torch.optim.Adam(embedding.parameters())\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e250447-6ebf-4cf2-ae22-19c2c282be1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
